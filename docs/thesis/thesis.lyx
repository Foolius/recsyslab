#LyX 2.0 created this file. For more info see http://www.lyx.org/
\lyxformat 413
\begin_document
\begin_header
\textclass scrreprt
\use_default_options true
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman default
\font_sans default
\font_typewriter default
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100

\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry false
\use_amsmath 1
\use_esint 1
\use_mhchem 1
\use_mathdots 1
\cite_engine basic
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\use_refstyle 1
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
Multi-purpose Library of Recommender System Algorithms for the Item Prediction
 Task
\end_layout

\begin_layout Author
Julius Kolbe
\end_layout

\begin_layout Date
11.6.2013
\end_layout

\begin_layout Standard
\begin_inset CommandInset toc
LatexCommand tableofcontents

\end_inset


\end_layout

\begin_layout Chapter
Abstract
\end_layout

\begin_layout Standard
In this thesis I will give an introduction to recommender systems, provide
 an overview over other recommender system libraries and datasets available
 to try out the algorithms.
 After that I will describe different recommender algorithms and evaluation
 metrics I implemented in my work followed by an explanation on how to use
 them.
 Additionally I will provide the result of the tests.
\end_layout

\begin_layout Chapter
Introduction
\end_layout

\begin_layout Section
Motivation
\end_layout

\begin_layout Standard
The library together with this document shall provide a 
\begin_inset Quotes eld
\end_inset

cookbook
\begin_inset Quotes erd
\end_inset

 for recommender systems.
 With the simple syntax and the interactivity of Python it is aimed at beginners
 to simply experiment with different algorithms.
 Especially the interactivity is missing in the already existing libraries
 because none of them is written in Python.
\end_layout

\begin_layout Section
Task (what a Recommender System does)
\end_layout

\begin_layout Standard
A Recommender System works in a scenario with users, items and interactions
 users can have with items.
 Such a scenario could be an online shop, where the interactions are purchases
 of items by users or a video platform, where the users interact with items
 (videos) by watching them.
 Based on the past interactions of the users a Recommender System searches
 for items a user haven't interacted with yet but the probability that he
 will interact is maximized.
\end_layout

\begin_layout Standard
The interactions can be implicit like purchases or clicks, then the scenario
 is also called item prediction.
 When the feedback is provided explicit like ratings the scenario is called
 rating prediction.
 In this work the focus lies on implicit feedback or item prediction.
 However ratings can be interpreted as the strength of implicit feedback.
 For example how often a user purchased an item.
 Some algorithms implemented in this library can use this information but
 none will explicitly predict ratings like it's usual in rating prediction
 scenarios.
\end_layout

\begin_layout Section
Contributions
\end_layout

\begin_layout Standard
The main contribution of my work is the interactive library I wrote 
\begin_inset CommandInset citation
LatexCommand cite
key "key-3"

\end_inset

.
 Also in this document I provide explanations about the algorithms implemented
 in the library and an extensive user manual of the library.
\end_layout

\begin_layout Chapter
Background
\end_layout

\begin_layout Section
Evaluation Methods
\end_layout

\begin_layout Standard
To evaluate a recommender algorithm we have to split up the database into
 one for training and one for evaluation.
 There are different methods to split the database but in the library only
 one is implemented.
\end_layout

\begin_layout Subsection
Leave-one-out Protocol
\end_layout

\begin_layout Standard
The Leave-one-out Protocol means, that we take one interaction of each user
 out of the database for training and use it for validation.
 The item the recommender has to predict is also called hidden item.
 
\end_layout

\begin_layout Standard
Now we can test for each user if the algorithm is capable to predict this
 missing interaction.
\end_layout

\begin_layout Subsection
Evaluation metrics
\end_layout

\begin_layout Standard
These are a selection of different metrics to rate the recommendations.
 By default the evaluations are executed with only one hidden item but generally
 the metrics should also work with more than just one.
\end_layout

\begin_layout Subsubsection
Hitrate/Recall@N
\end_layout

\begin_layout Standard
This metrics lets the recommender recommend N items.
 If the hidden item is under the N recommended items, the recommender got
 a hit 
\begin_inset CommandInset citation
LatexCommand cite
key "key-4,key-5"

\end_inset

.
 So the hitrate is 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\mathrm{\textrm{Hitrate}}=\frac{\mathrm{Number}ofhits}{Numberofhiddenitems}
\]

\end_inset


\end_layout

\begin_layout Standard
This metric is very intuitive you can for example imagine that you show
 the user 10 items then Recall@10 would be the chance of showing the user
 an item he will interact with.
 But this metric doesn't take the number of recommended items into account.
\end_layout

\begin_layout Subsubsection
Precision
\end_layout

\begin_layout Standard
The precision
\begin_inset CommandInset citation
LatexCommand cite
key "key-5"

\end_inset

 is 
\end_layout

\begin_layout Standard
\begin_inset Formula $\textrm{Precision}=\frac{\textrm{numberofhits}}{\textrm{numberofrecommendeditems}}$
\end_inset


\end_layout

\begin_layout Standard
As you can clearly see this metric is taken the number of recommended items
 into account.
 Which will probably lead to worse results as the number of recommended
 items increases.
\end_layout

\begin_layout Subsubsection
F1
\end_layout

\begin_layout Standard
The F1 metric
\begin_inset CommandInset citation
LatexCommand cite
key "key-5"

\end_inset

 tries to balance hitrate and precision by taking both into account.
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\textrm{F1}=\frac{2*\textrm{Hitrate}*\textrm{Precision}}{(\textrm{Recall}+\textrm{Precision})}
\]

\end_inset

 
\end_layout

\begin_layout Subsubsection
Mean Reciprocal Hitrate
\end_layout

\begin_layout Standard
This metric counts the hits but punishes them the more the lower they appear
 in the list of recommendations.
 So if the hidden item appears first in the list of recommendations the
 hit counts as one, but when it is in the second position the hit already
 counts only as one half and so on.
 
\end_layout

\begin_layout Subsubsection
Area under the ROC (AUC)
\end_layout

\begin_layout Standard
AUC
\begin_inset CommandInset citation
LatexCommand cite
key "key-10"

\end_inset

 counts the number of items the recommender rates higher than the hidden
 item, normalize it by the number of items the recommender can rate higher.
 Sum this up for every user and again normalize by the number of users.
\end_layout

\begin_layout Standard
To get an implicit score of each item the recommender recommends all items
 in a list sorted by decreasing score.
 This is in fact the same as for the other metrics only that the recommender
 can recommend as many items as possible.
\end_layout

\begin_layout Section
Datasets for testing
\end_layout

\begin_layout Standard
In the WWW there are several anonymized datasets available to try out recommende
r systems.
 Following I will introduce three of them.
\end_layout

\begin_layout Subsection
MovieLens
\end_layout

\begin_layout Standard
MovieLens
\begin_inset CommandInset citation
LatexCommand cite
key "key-12"

\end_inset

 is a database provided by GroupLens, a research lab at the University of
 Minnesota.
 One of their research areas is recommender systems and they built an applicatio
n where users rate movies and then get recommendations for movies the could
 like.
 The MovieLens dataset is the ratings gathered by this application.
 For this work I will interpret the rating as intensity of interaction between
 users and items for example the number of times the user saw this movie.
\end_layout

\begin_layout Standard
The dataset is available in three different sizes:
\end_layout

\begin_layout Itemize
100,000 ratings
\end_layout

\begin_layout Itemize
1 million ratings
\end_layout

\begin_layout Itemize
10 million ratings
\end_layout

\begin_layout Standard
For the experiments the smallest dataset is totally sufficient, with the
 larger datasets the computation time gets too long for just trying something
 out.
\end_layout

\begin_layout Subsection
Million Song Dataset
\end_layout

\begin_layout Subsection
SNAP
\end_layout

\begin_layout Chapter
Related Work
\end_layout

\begin_layout Standard
There is a wide range of projects providing implemantions for recommender
 system.
 Some of them are described in this chapter to give a quick overview and
 comparison.
\end_layout

\begin_layout Section
MyMediaLite
\end_layout

\begin_layout Standard
MyMediaLite
\begin_inset CommandInset citation
LatexCommand cite
key "key-1"

\end_inset

 is an open source project developed at the University of Hildesheim and
 provides several algorithm for rating prediction and item prediction.
 It is written in C# and is used with a command line interface.
 It also provides a graphical interface to demonstrate recommender algorithms
\end_layout

\begin_layout Section
PREA (Personalized Recommendation Algorithms Toolkit)
\end_layout

\begin_layout Standard
PREA
\begin_inset CommandInset citation
LatexCommand cite
key "key-2"

\end_inset

 is an open source project written in Java.
 It provides a wide range of recommender algorithms and evaluation metrics
 to test them.
 It is maintained by the Georgia Institute of Technology.
\end_layout

\begin_layout Section
Apache Mahout
\end_layout

\begin_layout Standard
Mahout
\begin_inset CommandInset citation
LatexCommand cite
key "key-6"

\end_inset

 is an open source library in java.
 It is implemented on top of Apache Hadoop, so it uses the map/reduce paradigm.
 This means it can run on different independent computers.
\end_layout

\begin_layout Section
Duine Framework
\end_layout

\begin_layout Standard
The Duine Framework 
\begin_inset CommandInset citation
LatexCommand cite
key "key-7"

\end_inset

 is an open source project written in java by the Telematica Instituut/Novay.
 The recommender of the Duine Framework combines multiple prediction techniques
 to exploit the strengths of the different techniques and to avoid their
 weaknesses.
\end_layout

\begin_layout Section
Cofi
\end_layout

\begin_layout Standard
Cofi 
\begin_inset CommandInset citation
LatexCommand cite
key "key-8"

\end_inset

provides an algorithm for the rating prediction task called Maximum Margin
 Matrix Factorization.
 It is open source and written in C++.
\end_layout

\begin_layout Section
LensKit
\end_layout

\begin_layout Standard
Lenskit 
\begin_inset CommandInset citation
LatexCommand cite
key "key-9"

\end_inset

 is a toolkit which provides several recommender algorithms and an infrastructur
e to evaluate them.
 It is an open source project by the University of Minnesota
\end_layout

\begin_layout Chapter
Recommendation Algorithms
\end_layout

\begin_layout Section
Non-Personalized Algorithms
\end_layout

\begin_layout Standard
In this chapter I will describe two very simple and basic recommendation
 algorithms I implemented for comparison with the more sophisticated algorithms.
\end_layout

\begin_layout Subsection
Constant
\end_layout

\begin_layout Standard
The constant recommender algorithm counts the number of interactions for
 each item and sorts this in decreasing order of interactions.
 Then it recommends the top items of this list.
 So it recommends the items which are the most popular over all users and
 doesn't do any personalizations.
\end_layout

\begin_layout Subsection
Random
\end_layout

\begin_layout Standard
The random recommender just picks items randomly.
\end_layout

\begin_layout Section
k-Nearest-Neighbor
\end_layout

\begin_layout Standard
This class of recommendation algorithms works by searching neighbors of
 either items or users based on a similarity function which is the cosine
 in this library.
\end_layout

\begin_layout Subsection
Item Based
\end_layout

\begin_layout Standard
For this algorithm the database has to be represented as a matrix where
 the rows correspond to the users and the columns to the items.
 Then the entry (i,j) represents the number of transactions which happened
 between the ith user and the jth item.
 
\end_layout

\begin_layout Standard
The algorithm interprets the columns of the matrix i.e.
 the items as vectors and computes there similarities by computing their
 cosine.
 To build the model the algorithm computes the n most similar items of each
 item.
 
\end_layout

\begin_layout Standard
To compute recommendations for user U the algorithm then computes the union
 of the n most similar items of each item U interacted with.
 From this set the items U already interacted with are removed.
 For each item remaining in this set we compute the sum of its similarities
 to the items U interacted with.
 Finally these items are sorted in decreasing order of this sum of similarities
 and the first n items will be recommended
\begin_inset CommandInset citation
LatexCommand cite
key "key-4"

\end_inset

.
\end_layout

\begin_layout Subsection
User Based
\end_layout

\begin_layout Standard
The user based k-Nearest-Neighbor is very similar to the item based.
 But instead of interpreting the columns as vectors we interpret the lines
 or users of the matrix as vectors and compute their similarities to other
 users.
\end_layout

\begin_layout Standard
Then for each item i we sum up the similarities between U and the users
 who interacted with i.
 Again we remove all items U already interacted with, sort in decreasing
 order fo the sum and recommend the first n items.
\end_layout

\begin_layout Section
Matrix Factorization
\end_layout

\begin_layout Standard
All matrix factorization techniques build two matrices in the model building
 phase.
 These matrices are supposed to represent abstract features of each item
 and user.
 For recommendation the dot product of the feature vector of an user and
 an item gives a score whith which we can sort the items and recommend the
 best suitable ones.
 The process of presenting a large matrix M as two smaller matrices W and
 H so that M = W*H is also called singular value decomposition.
\end_layout

\begin_layout Standard
Each of the implemented algorithms train the model with stochastic gradient
 descent.
 In each iteration the model is trained with a randomly chosen user, a randomly
 chosen item the user interacted with, called the positive item and a randomly
 chosen item the user didn't interacted with yet, called the negative item.
 The features of the user and the negative and the positive item are then
 trained according to the derivative of a loss function.
\end_layout

\begin_layout Subsection
BPRMF
\end_layout

\begin_layout Standard
BPMRF uses the logloss to train the model.
 The logloss is defined as
\begin_inset Formula 
\[
\textrm{logLoss}(a,y)=\log(1+\exp(-ay))
\]

\end_inset


\end_layout

\begin_layout Standard
And the derivative of the log loss is
\begin_inset Formula 
\[
\frac{\partial}{\partial y}(\log(1+\exp(-ay)))=-\frac{a}{\exp(ay)+1}
\]

\end_inset


\end_layout

\begin_layout Standard
For further informations please refer to 
\begin_inset CommandInset citation
LatexCommand cite
key "key-10"

\end_inset


\end_layout

\begin_layout Subsection
RankMFX
\end_layout

\begin_layout Standard
RankMFX uses the hingeLoss.
 It is defined as
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\mathrm{\textrm{hingeLoss}(a,y)=\max(0,1-ay)}
\]

\end_inset


\end_layout

\begin_layout Standard
And its derivative
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\frac{\partial}{\partial y}(\max(0,1-ay))=\begin{cases}
-y & ay<1\\
0 & \textrm{otherwise}
\end{cases}
\]

\end_inset


\end_layout

\begin_layout Standard
See also [Paper for citation?]
\end_layout

\begin_layout Subsection
Ranking SVD (Sparse SVD)
\end_layout

\begin_layout Standard
Ranking SVD uses the quadratic loss and the difference between the predicted
 score of the positive item and the negative minus the actual score of the
 positive item.
\begin_inset CommandInset citation
LatexCommand cite
key "key-11"

\end_inset


\end_layout

\begin_layout Chapter
Experiments
\end_layout

\begin_layout Section
Execution
\end_layout

\begin_layout Section
Results
\end_layout

\begin_layout Section
Comparison
\end_layout

\begin_layout Chapter
Design and Implementation
\end_layout

\begin_layout Section
General structure
\end_layout

\begin_layout Section
Interfaces
\end_layout

\begin_layout Chapter
User Manual
\end_layout

\begin_layout Section
Primitive Algorithms
\end_layout

\begin_layout Section
k-Nearest Neighbor
\end_layout

\begin_layout Section
BPRMF
\end_layout

\begin_layout Section
RankMFX
\end_layout

\begin_layout Section
Ranking SVD (Sparse SVD)
\end_layout

\begin_layout Chapter
Conclusions
\end_layout

\begin_layout Section
Future work
\end_layout

\begin_layout Section
Outlook
\end_layout

\begin_layout Chapter
References
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "key-1"

\end_inset

Zeno Gantner, Steffen Rendle, Christoph Freudenthaler, Lars Schmidt-Thieme:
 MyMediaLite: A Free Recommender System Library.
 RecSys 2011
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "key-2"

\end_inset

http://prea.gatech.edu/
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "key-6"

\end_inset

http://mahout.apache.org/
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "key-7"

\end_inset

http://www.duineframework.org/
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "key-8"

\end_inset

https://sites.google.com/a/cofirank.org/index/
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "key-9"

\end_inset

http://lenskit.grouplens.org/
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "key-3"

\end_inset

https://github.com/Foolius/recsyslab
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "key-4"

\end_inset

Evaluation of Item-Based Top-N Recommendation Algorithms by George Karypis
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "key-5"

\end_inset

Application of Dimensionality Reduction in Recommender System -- A Case
 Study by Badrul M.
 Sarwar et al
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "key-10"

\end_inset

BPR: Bayesian Personalized Ranking from Implicit Feedback from Steffen Rendle
 et al
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "key-11"

\end_inset

Collaborative Filtering Ensemble for Ranking by Michael Jahrer, Andreas
 TÃ¶scher
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "key-12"

\end_inset

http://grouplens.org/node/73
\end_layout

\end_body
\end_document
