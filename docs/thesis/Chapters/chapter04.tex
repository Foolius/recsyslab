
\chapter{Recommendation Algorithms}
\label{recommendationalgorithms}
In this chapter we will provide an overview on how the algorithms we implemented
work. To illustrate the simplicity of the code we will also show the core part of 
the source code of the respective recommender algorithm.
For further explanations please refer to the cited papers.


\section{Non-Personalized Algorithms}

In this chapter we will describe two very simple and basic recommendation
algorithms we implemented for comparison with the more sophisticated
algorithms.


\subsection{Constant}

The constant recommender algorithm counts the number of interactions
for each item and sorts this in decreasing order of interactions.
Then it recommends the top items of this list. So it recommends the
items which are the most popular over all users and does not do any
personalizations. The intuition here is that the most popular items
will be interesting for everyone. However the results show that
algorithms which personalize the recommendation based on the 
interaction history of the users perform much better.
In pseudocode this algorithm will look like this:
\begin{lstlisting}
countDict = dict initialized with all ItemIDs as keys and 0 as values

for interaction in dataset:
    countDict(ItemID(interaction))++

ranking = list(ItemIDs in decreasing order of their values)

return first N items of ranking
\end{lstlisting}
And the implementation:
\begin{lstlisting}
def __init__(self, dbdict):
    self.dictionary = {}
    self.sortedList = []
    for data in dbdict.iteritems():
        for item, rating in iter(data[1]):
            if item in self.dictionary:
                self.dictionary[item] += rating
            else:
                self.dictionary[item] = rating

    self.sortedList = helper.sortList(self.dictionary.iteritems())

def getRec(self, user, n):
    return self.sortedList[:n]
\end{lstlisting}



\subsection{Random}

The random recommender algorithm chooses items to recommend randomly.
Even though this algorithm will recommend different items for different
users it is not personalized because it the recommendations are
independent of the previous interactions of the user.
In pseudocode this will be:
\begin{lstlisting}
return N randomly chosen items
\end{lstlisting}
And in Python:
\begin{lstlisting}
def __init__(self, dbdict, seed):
    self.maxIid = 0
    self.seed = seed
    for data in dbdict.iteritems():
        for itemRating in iter(data[1]):
            item = itemRating[0]
            if item > self.maxIid:
                self.maxIid = item
    self.maxIid += 1

def getRec(self, user, n):
    random.seed(self.seed)
    if self.maxIid < n or n == -1:
        l = range(self.maxIid)
        random.shuffle(l)
        return l
    return list(random.sample(range(self.maxIid), n))
\end{lstlisting}


\section{k-Nearest-Neighbor}

This class of recommendation algorithms works by searching neighbors
of either items or users based on a similarity function which is the
cosine in this library. The similarity function is interchangeable 
for example in
\cite{Karypis:2001:EIT:502585.502627} two similarity functions are
compared. The cosine similarity performs best so in recsyslab only the cosine similarity
is implemented. For two vectors \(\overrightarrow{v},\overrightarrow{u}\)
The cosine similarity is defined as follows:

\begin{equation}
\cos(\overrightarrow{v}, \overrightarrow{u})=\frac{\overrightarrow{v} \cdot \overrightarrow{u}}{||\overrightarrow{v}||_{2} ||\overrightarrow{u}||_{2}}
\end{equation}
With the similarity it is possible to rank items.
In the Item Based algorithm for each item we compute the sum of 
similarities with the items the user already bought and rank 
accordingly.
In the User Based algorithm for every item we sum up the 
similarities of the user who bought this item and rank
according to this score.


\subsection{Item Based}
\label{itembasedknn}

For this algorithm the database has to be represented as a matrix
where the rows correspond to the users and the columns to the items.
Then the entry (i,j) represents the number of transactions which happened
between the ith user and the jth item. 

The algorithm interprets the columns of the matrix i.e. the items
as vectors and computes there similarities by computing their cosine.
To build the model the algorithm computes the n most similar items
of each item. In pseudocode:
\begin{lstlisting}
for every item i
    for every item j
        sim[i,j] = similarity between i and j

for every item i
    for every item j
        if sim[i,j] not one of the n largest in sim[i]
            sim[i,j] = 0
\end{lstlisting}
In Python it looks like this:
\begin{lstlisting}
def __init__(self, userItemMatrix, n):
    self.itemUserMatrix = userItemMatrix.transpose()
    self.sim = computeCosSim(self.sim, self.itemUserMatrix)
    self.userItemMatrix = userItemMatrix

    order = self.sim.argsort(1)

    # for each row in sim:
    # Set all entries to 0 except the n highest
    for j in xrange(0, self.sim.shape[1]):
        for i in xrange(0, self.sim.shape[1] - n):
            self.sim[j, order[j, i]] = 0
\end{lstlisting}
\lstinline!computeCosSim! looks like this:
\begin{lstlisting}
def computeCosSim(sim, matrix):
    for i in xrange(1, sim.shape[1]):

        for j in xrange(0, i):
            sim[i, j] = sim[j, i] = cos(
                matrix[i], matrix[j])
    return sim
\end{lstlisting}
This function is also used in the user based k-Nearest-Neighbor.


To compute recommendations for user U the algorithm computes
the union of the n most similar items of each item U interacted with.
From this set the items U already interacted with are removed. For
each item remaining in this set we compute the sum of its similarities
to the items U interacted with. Finally these items are sorted in
decreasing order of this sum of similarities and the first n items
will be recommended~\cite{Karypis:2001:EIT:502585.502627}.
The pseudocode is
\begin{lstlisting}
for every item i user u bought
    itemSimVector = itemSimVector + vector of i

for every item i user u bought
    itemSimVector[i] = 0

return the N items with the highest value in itemSimVector
\end{lstlisting}
The Python equivalent:
\begin{lstlisting}
def getRec(self, u, n):
    # x are the similarities of each item to the items u bought
    # w.r.t. only the highest n similarities are saved.
    x = self.userItemMatrix[u] * self.sim

    # Throw out items the user already purchased
    for i in xrange(0, self.sim.shape[0]):
        if self.userItemMatrix[u, i] != 0:
            x[0, i] = 0

    order = x.argsort()
    l = []
    for i in xrange(1, n + 1):
        l.append(order[0, -i])
    return l
\end{lstlisting}



\subsection{User Based}

The user based k-Nearest-Neighbor~\cite{userbasedknn} is very similar to the item based.
But instead of interpreting the columns as vectors we interpret the
lines or users of the matrix as vectors and compute their similarities
to other users.
Pseudocode:
\begin{lstlisting}
for every user u
    for every user o
        sim[u,o] = similarity between u and o

for every user u
    for every user o
        if sim[u,o] not one of the n largest in sim[u]]
            sim[u,o] = 0
\end{lstlisting}
Python:
\begin{lstlisting}
def __init__(self, userItemMatrix, n):
    self.userItemMatrix = userItemMatrix
    self.sim = np.zeros((userItemMatrix.shape[0], userItemMatrix.shape[0]))
    self.sim = computeCosSim(self.sim, self.userItemMatrix)

    order = self.sim.argsort(1)

    # for each row in sim:
    # Set all entries to 0 except the n highest
    for j in xrange(0, self.sim.shape[1]):
        for i in xrange(0, self.sim.shape[1] - n):
            self.sim[j, order[j, i]] = 0
\end{lstlisting}


Then for each item i we sum up the similarities between U and the
users who interacted with i. Again we remove all items U already interacted
with, sort in decreasing order fo the sum and recommend the first
n items.
Pseudocode:
\begin{lstlisting}
for every item i 
    for every user o
        score(i) = score(i) + sim[U,o]

for every item i user u bought
    score(i) = 0

return the N items with the highest value in score
\end{lstlisting}
Python:
\begin{lstlisting}
def getRec(self, u, n):
    # x is the weighted sum of the items
    # weighted with the similarity between u and the
    # other users.
    x = self.sim[u] * self.userItemMatrix

    for i in xrange(0, self.sim.shape[0]):
        if self.userItemMatrix[u, i] != 0:
            x[0, i] = 0

    order = x.argsort()
    l = []
    for i in xrange(1, n + 1):
        l.append(order[0, -i])

    return l
\end{lstlisting}

\section{Matrix Factorization}
As mentioned in \ref{matrixfactorization} the matrix factorization
techniques generate two matrices \(W\) and \(H\) so that \(M = W \times H\).
Each of the implemented algorithms train these two matrices with stochastic
gradient descent. In each iteration the model is trained with
\begin{itemize} 
    \item a randomly chosen user U
    \item a randomly chosen item I the user U interacted with, called the positive item and 
    \item a randomly chosen item J the user U did not already interacted with, 
        called the negative item.
\end{itemize}
The features of U, I and J are trained using the derivative
of a loss function.

BPRMF and RankMFX are sharing the code in the module \lstinline!recommender.mf!. 
The only difference is the loss function.
In pseudocode the model update happening in each iteration looks like this:
\begin{lstlisting}
U = randomly chosen user
I = randomly chosen item U interacted with
J = randomly chosen item U did not interact with

X=H[i] - H[j]
wx = dot product of W[u] and X
dloss = (derivative of the loss function of wx and 1) * learningRate

W[u] += dloss * (H[i] - H[j]) # These three lines
H[i] += dloss * W[u]          # have to be
H[j] += dloss * -W[u]         # executed at once
\end{lstlisting}
The Python code doing the same looks like this:
\begin{lstlisting}
u = random.choice(R.keys())

userItems = [x[0] for x in R[u]]
# the positive example
i = userItems[np.random.random_integers(0, len(userItems) - 1)]
# the negative example
j = np.random.random_integers(0, m_items)
# if  j is also relevant for u we continue
# we need to see a negative example to contrast the positive one
while j in userItems:
    j = np.random.random_integers(0, m_items)

X = H[i] - H[j]
wx = np.dot(W[u], X)
dloss = dlossF(wx, y)

# temp
wu = W[u]
hi = H[i]
hj = H[j]

if dloss != 0.0:
    # Updates
    eta_dloss = learningRate * dloss
    W[u] += eta_dloss * (hi - hj)
    H[i] += eta_dloss * wu
    H[j] += eta_dloss * (-wu)

    W[u] *= scaling_factorU
    H[i] *= scaling_factorI
    H[j] *= scaling_factorJ
\end{lstlisting}
For the recommendations we rank the items with a score.
The score of an item for a user is the dot
product of the feature vector of the user 
and the feature vector of the item. All matrix factorization
algorithms use this.
In pseudocode:
\begin{lstlisting}
for every item i
    scoreList(i) = W[u] * H[i]

sortByScore(score)
return first N of score
\end{lstlisting}
And in Python:
\begin{lstlisting}
def getRec(self, u, n):
    scoredict = {}
    for i in range(0, self.H.shape[0]):
        if not i in [x[0] for x in self.R[u]]:
            scoredict[i] = np.dot(self.W[u], self.H[i])

    if n == -1:
        n = len(scoredict)
    import util.helper
    return util.helper.sortList(scoredict.iteritems())[:n]
\end{lstlisting}


\subsection{BPRMF}

BPMRF uses the logloss to train the model. The logloss is defined
as
\begin{equation}
\textrm{logLoss}(a,y)=\log(1+\exp(-ay))
\end{equation}


And the derivative of the log loss is
\begin{equation}
\frac{\partial}{\partial y}(\log(1+\exp(-ay)))=-\frac{a}{\exp(ay)+1}
\end{equation}

For further informations please refer to~\cite{Rendle:2009:BBP:1795114.1795167}


\subsection{RankMFX}

RankMFX uses the hingeLoss. It is defined as

\begin{equation}
\mathrm{\textrm{hingeLoss}(a,y)=\max(0,1-ay)}
\end{equation}

And its derivative

\begin{equation}
\frac{\partial}{\partial y}(\max(0,1-ay))=\begin{cases}
-y & ay<1\\
0 & \textrm{otherwise}
\end{cases}
\end{equation}


See also~\cite{diaz2012happening}.


\subsection{Ranking SVD (Sparse SVD)}

Ranking SVD uses the quadratic loss and the difference between the
predicted score of the positive item and the negative minus the actual
score of the positive item~\cite{jahrer2011collaborative}.
Ranking SVD uses another code than BPRMF and RankMFX but the iterations
work the same. It also randomly chooses a user and a positive and a
negative item in each iteration of the stochastic gradient descent. 
But the model updates are different. In pseudocode:
\begin{lstlisting}
U = randomly chosen user
I = randomly chosen item U interacted with
J = randomly chosen item U did not interact with

ruipred = W[U] * H[I] # Prediction for item I
rui0pred = W[U] * H[J] # Prediction for item J
rui = actual value of the interaction between U and I 
ruj = 0

dloss = (ruipred - rujpred) - (rui - ruj)
W[U] = W[U] - learningRate * dloss * (H[I] - H[J])
H[I] = H[I] - learningRate * dloss * W[U]
H[J] = H[J] - learningRate * dloss * -W[U]
\end{lstlisting}
And in Python this part looks like this:
\begin{lstlisting}
# Choose an user randomly
u = random.choice(R.keys())
# Choose an item the user interacted with
userItems = [x[0] for x in R[u]]
i = random.choice(userItems)
# Choose an item, the user didn't interacted with
i0 = np.random.random_integers(0, m_items - 1)
while i0 in userItems:
    i0 = np.random.random_integers(0, m_items - 1)

# Prediction for the first item
ruipred = userFeatures[u].dot(itemFeatures[i])
# Prediction for the second item
rui0pred = userFeatures[u].dot(itemFeatures[i0])
rui0 = 0
for r in R[u]:
    if r[0] == i:
        rui = r[1]

dloss = (ruipred - rui0pred) - (rui - rui0)
c = userFeatures[u]
userFeatures -= learningRate * dloss * (
    itemFeatures[i] - itemFeatures[i0])
itemFeatures[i] -= learningRate * dloss * c
itemFeatures[i0] -= learningRate * dloss * (-c)
\end{lstlisting}


\section{Other}
In this chapter we will describe one last algorithm 
which does not fit into the above categories.
\subsection{Slope One}
The Slope One recommendation algorithm computes the differences of
interaction intensities between items and uses these differences to 
predict indirectly the interaction intensity between users and items
without any interaction~\cite{DBLP:journals/corr/abs-cs-0702144}.
The model building in pseudocode:
\begin{lstlisting}
for all interaction pairs i, j where i != j
    diffs[i][j] = i.rating - j.rating
    count[i][j]++
\end{lstlisting}
And in Python:
\begin{lstlisting}
def __init__(self, R):
    self.diffs = {}
    self.R = R

    for u in R.keys():
        for i, r in R[u]:
            if not i in self.diffs:
                self.diffs[i] = {}

            for i1, r1 in R[u]:
                if i == i1:
                    continue
                if not i1 in self.diffs[i]:
                    self.diffs[i][i1] = [0.0, 0.0]

                self.diffs[i][i1][0] += r - r1
                self.diffs[i][i1][1] += 1
\end{lstlisting}
For the recommendations for every item we sum up its differences with
the items the user rated together with the rating, the user gave these
other items. Additionaly this is multiplied by the number of times the
difference occured. This is then normalized by the sum of the occurrences
of the differences. Following is pseudocode to clarify this.
\begin{lstlisting}
for every item i
    ratingSum = 0
    count = 0
    for every item j user u interacted with
        ratingSum = ratingSum + ((rating u gave j) 
                              + diffs[i][j])
                              * count[i][j]
        count = count + count[i][j]

    ratingSum /= count
    listToRecommend.add( (i, ratingSum))

sortAfterRatingSum(listToRecommend)
return first N of listToRecommend
\end{lstlisting}
And in python:
\begin{lstlisting}
def getRec(self, u, n):
    maxIid = max(self.diffs.keys())
    userItems = [x[0] for x in self.R[u]]
    predictionList = []

    for i in xrange(0, maxIid + 1):
        if i in userItems:
            continue

        ratingSum = 0
        count = 0
        for i1, r in self.R[u]:
            if i in self.diffs:
                if i1 in self.diffs[i]:
                    ratingSum += (r + self.diffs[i][i1][0]
                                    ) * self.diffs[i][i1][1]
                    count += self.diffs[i][i1][1]

        if count == 0:
            continue
        ratingSum /= count
        predictionList.append((i, ratingSum))

    import util.helper
    sortedList = util.helper.sortList(predictionList)

    return sortedList[:n]
\end{lstlisting}
