\chapter{Experiments}
\label{experiments}
In this chapter we will show test results of every metric with every
recommender algorithm and how they were computed.


\section{Execution}
The results were computed using the recommender algorithms and 
the test metrics implemented in recsyslab. It was done 
like it is shown in the user manual in Chapter~\ref{usermanual}.
with exact the same parameters.

The only difference is that for simplification the different
\lstinline!getRec! methods and metric methods were each in a list and the 
algorithm is iterating trough both in two nested for loops
to guarantee that every algorithm is tested with every metric.
The code which generated the table in~\ref{results} is in 
the \lstinline!experiments.py! file in the \lstinline!bin! directory of recsyslab.
So check it out for further implementation details.


\section{Results}
\label{results}
Here are the results of every test metric in recsyslab
with every recommender algorithm in recsyslab.

%\vspace{1.5 mm}
\begin{table}[h]
\begin{tabular}{rlllll}
    recommender  & hitrate & precision & f1 & mrhr & auc \\ \midrule
    constant & 0.0731 & 0.0073 & 0.1448 & 0.0207 & 0.8263 \\
    randomRec & 0.0053 & 0.0005 & 0.0104 & 0.0011 & 0.4790 \\
    itemKnn & 0.2576 & 0.0257 & 0.5099 & 0.1151 & 0.8687 \\
    userKnn & 0.2619 & 0.0261 & 0.5183 & 0.1203 & 0.9279 \\
    BPRMF& 0.2492 & 0.0249 & 0.4931 & 0.0996 & 0.9294 \\
    RankMFX & 0.1792 & 0.0179 & 0.3546 & 0.0686 & 0.8295 \\
    Ranking SVD & 0.1198 & 0.0119 & 0.2371 & 0.0339 & 0.7725 \\
    slopeone & 0.0858 & 0.0085 & 0.1699 & 0.0350 & 0.4699 \\ \bottomrule
\end{tabular}
\caption{Results of every test metric with every recommender algorithm of recsyslab}
\end{table}
\newpage
\section{Comparison}
To show the performance of recsyslab we compare our test results with results 
from this paper:~\cite{deshpande2004item}

%\vspace{1.5 mm}
\begin{table}[h]
\begin{tabular}{rllll} \toprule
 & \multicolumn{2}{c}{hitrate} & \multicolumn{2}{c}{mrhr} \\ \cmidrule(r){2-3} \cmidrule(r){4-5}
 & recsyslab & \cite{deshpande2004item} & recsyslab & \cite{deshpande2004item} \\ \midrule
    constant & 0.0731 & 0.131 & 0.0207 & 0.046 \\
    itemKnn & 0.2576 & 0.271 & 0.1151 & 0.119 \\
    userKnn & 0.2619 & 0.281 & 0.1203 & 0.128 \\ \bottomrule
\end{tabular}
\caption{Comparison of some test results with results computed by someone else.}
\end{table}
%\vspace{1.5 mm}

It can be seen that recsyslab performs almost as good as the reference.
The small advantage probably comes from normalization we did not use when
we were computing these results.
